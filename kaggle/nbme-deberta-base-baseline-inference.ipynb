{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cbefb0",
   "metadata": {
    "papermill": {
     "duration": 0.031301,
     "end_time": "2022-02-16T23:55:21.575424",
     "exception": false,
     "start_time": "2022-02-16T23:55:21.544123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook\n",
    "- Deberta-base starter code\n",
    "- pip wheels is [here](https://www.kaggle.com/yasufuminakama/nbme-pip-wheels)\n",
    "- Training notebook is [here](https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train)\n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cf9b9",
   "metadata": {
    "papermill": {
     "duration": 0.017758,
     "end_time": "2022-02-16T23:55:21.618273",
     "exception": false,
     "start_time": "2022-02-16T23:55:21.600515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8c0dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:21.667733Z",
     "iopub.status.busy": "2022-02-16T23:55:21.666929Z",
     "iopub.status.idle": "2022-02-16T23:55:21.671060Z",
     "shell.execute_reply": "2022-02-16T23:55:21.670554Z",
     "shell.execute_reply.started": "2022-02-16T23:51:28.148154Z"
    },
    "papermill": {
     "duration": 0.034527,
     "end_time": "2022-02-16T23:55:21.671180",
     "exception": false,
     "start_time": "2022-02-16T23:55:21.636653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    num_workers=0\n",
    "    path=\"../input/nbme-deberta-base-baseline-train/\"\n",
    "    config_path='../input/nbme-deberta-base/ROBERTA-BASE_SCHEDULER_cos_ann_warm_config.pth'\n",
    "    model=\"microsoft/deberta-base\"\n",
    "    batch_size=24\n",
    "    fc_dropout=0.2\n",
    "    max_len=466\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcc3cf",
   "metadata": {
    "papermill": {
     "duration": 0.018138,
     "end_time": "2022-02-16T23:55:21.707828",
     "exception": false,
     "start_time": "2022-02-16T23:55:21.689690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f869055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:21.757280Z",
     "iopub.status.busy": "2022-02-16T23:55:21.756739Z",
     "iopub.status.idle": "2022-02-16T23:55:28.809214Z",
     "shell.execute_reply": "2022-02-16T23:55:28.809759Z",
     "shell.execute_reply.started": "2022-02-16T23:51:56.563949Z"
    },
    "papermill": {
     "duration": 7.083692,
     "end_time": "2022-02-16T23:55:28.809934",
     "exception": false,
     "start_time": "2022-02-16T23:55:21.726242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.10.3\n",
      "transformers.__version__: 4.12.5\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# os.system('pip uninstall -y transformers')\n",
    "# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e4a998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:28.852868Z",
     "iopub.status.busy": "2022-02-16T23:55:28.852242Z",
     "iopub.status.idle": "2022-02-16T23:55:28.855762Z",
     "shell.execute_reply": "2022-02-16T23:55:28.855297Z",
     "shell.execute_reply.started": "2022-02-16T23:52:03.888716Z"
    },
    "papermill": {
     "duration": 0.026561,
     "end_time": "2022-02-16T23:55:28.855877",
     "exception": false,
     "start_time": "2022-02-16T23:55:28.829316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../input/nbme-deberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27353b33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:28.897639Z",
     "iopub.status.busy": "2022-02-16T23:55:28.896909Z",
     "iopub.status.idle": "2022-02-16T23:55:28.898888Z",
     "shell.execute_reply": "2022-02-16T23:55:28.899324Z",
     "shell.execute_reply.started": "2022-02-16T23:52:03.896031Z"
    },
    "papermill": {
     "duration": 0.024647,
     "end_time": "2022-02-16T23:55:28.899460",
     "exception": false,
     "start_time": "2022-02-16T23:55:28.874813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb41749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:28.940776Z",
     "iopub.status.busy": "2022-02-16T23:55:28.940129Z",
     "iopub.status.idle": "2022-02-16T23:55:28.947334Z",
     "shell.execute_reply": "2022-02-16T23:55:28.946932Z",
     "shell.execute_reply.started": "2022-02-16T23:52:03.911378Z"
    },
    "papermill": {
     "duration": 0.029337,
     "end_time": "2022-02-16T23:55:28.947437",
     "exception": false,
     "start_time": "2022-02-16T23:55:28.918100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_li = sorted(pathlib.Path('../input/nbme-deberta-base').glob('*FOLD*.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f2232",
   "metadata": {
    "papermill": {
     "duration": 0.019083,
     "end_time": "2022-02-16T23:55:28.986470",
     "exception": false,
     "start_time": "2022-02-16T23:55:28.967387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8004539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:29.027965Z",
     "iopub.status.busy": "2022-02-16T23:55:29.027345Z",
     "iopub.status.idle": "2022-02-16T23:55:29.183572Z",
     "shell.execute_reply": "2022-02-16T23:55:29.182972Z",
     "shell.execute_reply.started": "2022-02-16T23:52:03.920222Z"
    },
    "papermill": {
     "duration": 0.178497,
     "end_time": "2022-02-16T23:55:29.183783",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.005286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd494851",
   "metadata": {
    "papermill": {
     "duration": 0.019159,
     "end_time": "2022-02-16T23:55:29.222858",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.203699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfc231c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:29.272718Z",
     "iopub.status.busy": "2022-02-16T23:55:29.270153Z",
     "iopub.status.idle": "2022-02-16T23:55:29.275477Z",
     "shell.execute_reply": "2022-02-16T23:55:29.274991Z",
     "shell.execute_reply.started": "2022-02-16T23:52:04.084470Z"
    },
    "papermill": {
     "duration": 0.033531,
     "end_time": "2022-02-16T23:55:29.275631",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.242100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a093d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:29.333781Z",
     "iopub.status.busy": "2022-02-16T23:55:29.333032Z",
     "iopub.status.idle": "2022-02-16T23:55:29.335787Z",
     "shell.execute_reply": "2022-02-16T23:55:29.335301Z",
     "shell.execute_reply.started": "2022-02-16T23:52:04.096033Z"
    },
    "papermill": {
     "duration": 0.03922,
     "end_time": "2022-02-16T23:55:29.335912",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.296692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132775b",
   "metadata": {
    "papermill": {
     "duration": 0.018307,
     "end_time": "2022-02-16T23:55:29.374230",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.355923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87838cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:29.419870Z",
     "iopub.status.busy": "2022-02-16T23:55:29.414361Z",
     "iopub.status.idle": "2022-02-16T23:55:29.424684Z",
     "shell.execute_reply": "2022-02-16T23:55:29.424170Z",
     "shell.execute_reply.started": "2022-02-16T23:52:04.115995Z"
    },
    "papermill": {
     "duration": 0.031814,
     "end_time": "2022-02-16T23:55:29.424811",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.392997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename='inference'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aff5e3",
   "metadata": {
    "papermill": {
     "duration": 0.018706,
     "end_time": "2022-02-16T23:55:29.462435",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.443729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1895ca01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:55:29.507321Z",
     "iopub.status.busy": "2022-02-16T23:55:29.506808Z",
     "iopub.status.idle": "2022-02-16T23:56:13.745386Z",
     "shell.execute_reply": "2022-02-16T23:56:13.744941Z",
     "shell.execute_reply.started": "2022-02-16T23:52:04.129668Z"
    },
    "papermill": {
     "duration": 44.264175,
     "end_time": "2022-02-16T23:56:13.745539",
     "exception": false,
     "start_time": "2022-02-16T23:55:29.481364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "th: 0.45  score: 0.86036\n",
      "th: 0.46  score: 0.86051\n",
      "th: 0.47  score: 0.86052\n",
      "th: 0.48  score: 0.86065\n",
      "th: 0.49  score: 0.86067\n",
      "th: 0.5  score: 0.86076\n",
      "th: 0.51  score: 0.86075\n",
      "th: 0.52  score: 0.86051\n",
      "th: 0.53  score: 0.86025\n",
      "th: 0.54  score: 0.86027\n",
      "th: 0.55  score: 0.86002\n",
      "best_th: 0.5  score: 0.86076\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# oof\n",
    "# ====================================================\n",
    "oof = pd.read_pickle(CFG.path+'oof_df.pkl')\n",
    "\n",
    "truths = create_labels_for_scoring(oof)\n",
    "char_probs = get_char_probs(oof['pn_history'].values,\n",
    "                            oof[[i for i in range(CFG.max_len)]].values, \n",
    "                            CFG.tokenizer)\n",
    "best_th = 0.5\n",
    "best_score = 0.\n",
    "for th in np.arange(0.45, 0.55, 0.01):\n",
    "    th = np.round(th, 2)\n",
    "    results = get_results(char_probs, th=th)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(preds, truths)\n",
    "    if best_score < score:\n",
    "        best_th = th\n",
    "        best_score = score\n",
    "    LOGGER.info(f\"th: {th}  score: {score:.5f}\")\n",
    "LOGGER.info(f\"best_th: {best_th}  score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7752e37",
   "metadata": {
    "papermill": {
     "duration": 0.021825,
     "end_time": "2022-02-16T23:56:13.789935",
     "exception": false,
     "start_time": "2022-02-16T23:56:13.768110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f1ad7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:13.841210Z",
     "iopub.status.busy": "2022-02-16T23:56:13.840687Z",
     "iopub.status.idle": "2022-02-16T23:56:14.505278Z",
     "shell.execute_reply": "2022-02-16T23:56:14.505701Z",
     "shell.execute_reply.started": "2022-02-16T23:52:47.637566Z"
    },
    "papermill": {
     "duration": 0.693971,
     "end_time": "2022-02-16T23:56:14.505846",
     "exception": false,
     "start_time": "2022-02-16T23:56:13.811875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (5, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num\n",
       "0  00016_000         0      16            0\n",
       "1  00016_001         0      16            1\n",
       "2  00016_002         0      16            2\n",
       "3  00016_003         0      16            3\n",
       "4  00016_004         0      16            4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (143, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_notes.shape: (42146, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "test = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\n",
    "submission = pd.read_csv('../input/nbme-score-clinical-patient-notes/sample_submission.csv')\n",
    "features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\n",
    "def preprocess_features(features):\n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "features = preprocess_features(features)\n",
    "patient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n",
    "\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "display(test.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f7413dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:14.568004Z",
     "iopub.status.busy": "2022-02-16T23:56:14.561784Z",
     "iopub.status.idle": "2022-02-16T23:56:14.584287Z",
     "shell.execute_reply": "2022-02-16T23:56:14.584820Z",
     "shell.execute_reply.started": "2022-02-16T23:52:48.327239Z"
    },
    "papermill": {
     "duration": 0.054666,
     "end_time": "2022-02-16T23:56:14.584961",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.530295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                                       feature_text                                         pn_history\n",
       "0  00016_000         0      16            0  Family-history-of-MI-OR-Family-history-of-myoc...  HPI: 17yo M presents with palpitations. Patien...\n",
       "1  00016_001         0      16            1                 Family-history-of-thyroid-disorder  HPI: 17yo M presents with palpitations. Patien...\n",
       "2  00016_002         0      16            2                                     Chest-pressure  HPI: 17yo M presents with palpitations. Patien...\n",
       "3  00016_003         0      16            3                              Intermittent-symptoms  HPI: 17yo M presents with palpitations. Patien...\n",
       "4  00016_004         0      16            4                                        Lightheaded  HPI: 17yo M presents with palpitations. Patien..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = test.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "test = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde6401",
   "metadata": {
    "papermill": {
     "duration": 0.024338,
     "end_time": "2022-02-16T23:56:14.634055",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.609717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e03a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:14.691241Z",
     "iopub.status.busy": "2022-02-16T23:56:14.690482Z",
     "iopub.status.idle": "2022-02-16T23:56:14.693141Z",
     "shell.execute_reply": "2022-02-16T23:56:14.692661Z",
     "shell.execute_reply.started": "2022-02-16T23:52:48.357607Z"
    },
    "papermill": {
     "duration": 0.034495,
     "end_time": "2022-02-16T23:56:14.693245",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.658750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text, feature_text):\n",
    "    inputs = cfg.tokenizer(text, feature_text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.feature_texts = df['feature_text'].values\n",
    "        self.pn_historys = df['pn_history'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.pn_historys[item], \n",
    "                               self.feature_texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0291895",
   "metadata": {
    "papermill": {
     "duration": 0.024626,
     "end_time": "2022-02-16T23:56:14.742948",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.718322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a38b4750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:14.805676Z",
     "iopub.status.busy": "2022-02-16T23:56:14.803996Z",
     "iopub.status.idle": "2022-02-16T23:56:14.806240Z",
     "shell.execute_reply": "2022-02-16T23:56:14.806657Z",
     "shell.execute_reply.started": "2022-02-16T23:52:48.366865Z"
    },
    "papermill": {
     "duration": 0.038806,
     "end_time": "2022-02-16T23:56:14.806777",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.767971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abcfaf",
   "metadata": {
    "papermill": {
     "duration": 0.025141,
     "end_time": "2022-02-16T23:56:14.856470",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.831329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e822a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:14.913577Z",
     "iopub.status.busy": "2022-02-16T23:56:14.911973Z",
     "iopub.status.idle": "2022-02-16T23:56:14.914243Z",
     "shell.execute_reply": "2022-02-16T23:56:14.914743Z",
     "shell.execute_reply.started": "2022-02-16T23:52:48.381469Z"
    },
    "papermill": {
     "duration": 0.033212,
     "end_time": "2022-02-16T23:56:14.914865",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.881653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "#     tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in test_loader:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4d1b86",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-16T23:56:14.972978Z",
     "iopub.status.busy": "2022-02-16T23:56:14.972116Z",
     "iopub.status.idle": "2022-02-16T23:57:45.554305Z",
     "shell.execute_reply": "2022-02-16T23:57:45.553843Z",
     "shell.execute_reply.started": "2022-02-16T23:52:48.392745Z"
    },
    "papermill": {
     "duration": 90.614971,
     "end_time": "2022-02-16T23:57:45.554441",
     "exception": false,
     "start_time": "2022-02-16T23:56:14.939470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb696b628b040f3a45df59be298eb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in tqdm(CFG.trn_fold, total=len(CFG.trn_fold)):\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    checkpoint_path = models_li[fold]\n",
    "#     state = torch.load(checkpoint_path, map_location=torch.device('cpu')).state_dict()\n",
    "    state = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state)\n",
    "    \n",
    "    prediction = inference_fn(test_loader, model, 'cpu')\n",
    "    prediction = prediction.reshape((len(test), CFG.max_len))\n",
    "    char_probs = get_char_probs(test['pn_history'].values, prediction, CFG.tokenizer)\n",
    "    predictions.append(char_probs)\n",
    "    del model, prediction, char_probs; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef29a09",
   "metadata": {
    "papermill": {
     "duration": 0.024921,
     "end_time": "2022-02-16T23:57:45.605340",
     "exception": false,
     "start_time": "2022-02-16T23:57:45.580419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3618d0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T23:57:45.664648Z",
     "iopub.status.busy": "2022-02-16T23:57:45.664095Z",
     "iopub.status.idle": "2022-02-16T23:57:45.671291Z",
     "shell.execute_reply": "2022-02-16T23:57:45.670861Z",
     "shell.execute_reply.started": "2022-02-16T23:54:22.151525Z"
    },
    "papermill": {
     "duration": 0.041173,
     "end_time": "2022-02-16T23:57:45.671393",
     "exception": false,
     "start_time": "2022-02-16T23:57:45.630220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>696 724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>668 693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>203 217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>70 91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id location\n",
       "0  00016_000  696 724\n",
       "1  00016_001  668 693\n",
       "2  00016_002  203 217\n",
       "3  00016_003    70 91\n",
       "4  00016_004         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = get_results(predictions, th=best_th)\n",
    "submission['location'] = results\n",
    "display(submission.head())\n",
    "submission[['id', 'location']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02d045",
   "metadata": {
    "papermill": {
     "duration": 0.025972,
     "end_time": "2022-02-16T23:57:45.722995",
     "exception": false,
     "start_time": "2022-02-16T23:57:45.697023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.420002,
   "end_time": "2022-02-16T23:57:48.761260",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-16T23:55:13.341258",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "553a956fa7994b0f84291b4097acd07e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "675b11a430cf4683aba4ef9a4c1e8ca0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69e9fc21b28249289381c314784ea3f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ef3a0b67de945deb50024dc098f88ce",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d7282920bc7a41d69b4cf8d5c63a0135",
       "value": 5.0
      }
     },
     "6d2277cbae7c4ad6840637689f1dd326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_675b11a430cf4683aba4ef9a4c1e8ca0",
       "placeholder": "",
       "style": "IPY_MODEL_553a956fa7994b0f84291b4097acd07e",
       "value": " 5/5 [01:30&lt;00:00, 17.20s/it]"
      }
     },
     "7ef3a0b67de945deb50024dc098f88ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c12ddd662367418f92b2e9ce854982f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf09d057065b4c81b1059d5373e7ea8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db1a23aaea044d268fff960c25051b17",
       "placeholder": "",
       "style": "IPY_MODEL_e6c03fa69f93479cbdf170ab0b954fc8",
       "value": "100%"
      }
     },
     "d7282920bc7a41d69b4cf8d5c63a0135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db1a23aaea044d268fff960c25051b17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfb696b628b040f3a45df59be298eb9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cf09d057065b4c81b1059d5373e7ea8f",
        "IPY_MODEL_69e9fc21b28249289381c314784ea3f5",
        "IPY_MODEL_6d2277cbae7c4ad6840637689f1dd326"
       ],
       "layout": "IPY_MODEL_c12ddd662367418f92b2e9ce854982f4"
      }
     },
     "e6c03fa69f93479cbdf170ab0b954fc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
