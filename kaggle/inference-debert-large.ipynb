{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n","\n","input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n","    if str(filename).startswith(\"deberta\"):\n","        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n","    else:\n","        filepath = deberta_v2_path/filename\n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016162,"end_time":"2021-11-16T19:32:40.221507","exception":false,"start_time":"2021-11-16T19:32:40.205345","status":"completed"},"tags":[]},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:01:27.184921Z","iopub.status.busy":"2022-02-25T12:01:27.184385Z","iopub.status.idle":"2022-02-25T12:01:35.432839Z","shell.execute_reply":"2022-02-25T12:01:35.431959Z","shell.execute_reply.started":"2022-02-25T12:01:27.184886Z"},"papermill":{"duration":30.77583,"end_time":"2021-11-16T19:33:11.013554","exception":false,"start_time":"2021-11-16T19:32:40.237724","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","# os.system('pip uninstall -y transformers')\n","# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:06:20.956152Z","iopub.status.busy":"2022-02-25T12:06:20.955875Z","iopub.status.idle":"2022-02-25T12:06:20.966255Z","shell.execute_reply":"2022-02-25T12:06:20.965447Z","shell.execute_reply.started":"2022-02-25T12:06:20.956122Z"},"papermill":{"duration":0.02543,"end_time":"2021-11-16T19:32:30.040766","exception":false,"start_time":"2021-11-16T19:32:30.015336","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    num_workers=4\n","    dir_path=\"../input/debertav3largebs16\" # add the directory path of your own files in kaggle dataset\n","    token_path=\"../input/get-token\" # add the directory path of saved tokenizer\n","    config_path= os.path.join(dir_path, [f for f in os.listdir(dir_path) if f.endswith('config.pth')][0])\n","    model=\"microsoft/deberta-v3-large\"\n","    oof_path = os.path.join(dir_path, [f for f in os.listdir(dir_path) if f.endswith('.pkl')][0])\n","    trained_models = [f for f in os.listdir(dir_path) if (f.endswith('.pth')) & ('FOLD' in f)]\n","    batch_size=16\n","    fc_dropout=0.2\n","    max_len=354\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]"]},{"cell_type":"markdown","metadata":{},"source":["# tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:11:06.871978Z","iopub.status.busy":"2022-02-25T12:11:06.87166Z","iopub.status.idle":"2022-02-25T12:11:14.971357Z","shell.execute_reply":"2022-02-25T12:11:14.970348Z","shell.execute_reply.started":"2022-02-25T12:11:06.871947Z"},"trusted":true},"outputs":[],"source":["from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.token_path)\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01915,"end_time":"2021-11-16T19:33:11.052159","exception":false,"start_time":"2021-11-16T19:33:11.033009","status":"completed"},"tags":[]},"source":["# Helper functions for scoring"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:11:14.973238Z","iopub.status.busy":"2022-02-25T12:11:14.973002Z","iopub.status.idle":"2022-02-25T12:11:14.983682Z","shell.execute_reply":"2022-02-25T12:11:14.982684Z","shell.execute_reply.started":"2022-02-25T12:11:14.973207Z"},"trusted":true},"outputs":[],"source":["# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n","\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:11:14.985928Z","iopub.status.busy":"2022-02-25T12:11:14.985391Z","iopub.status.idle":"2022-02-25T12:11:15.003351Z","shell.execute_reply":"2022-02-25T12:11:15.002784Z","shell.execute_reply.started":"2022-02-25T12:11:14.985881Z"},"trusted":true},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, 'location']\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","    return truths\n","\n","\n","def get_char_probs(texts, predictions, tokenizer):\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(text, \n","                            add_special_tokens=True,\n","                            return_offsets_mapping=True)\n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","            results[i][start:end] = pred\n","    return results\n","\n","\n","def get_results(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:11:15.006022Z","iopub.status.busy":"2022-02-25T12:11:15.005491Z","iopub.status.idle":"2022-02-25T12:11:15.026832Z","shell.execute_reply":"2022-02-25T12:11:15.02607Z","shell.execute_reply.started":"2022-02-25T12:11:15.005977Z"},"papermill":{"duration":0.034649,"end_time":"2021-11-16T19:33:11.105766","exception":false,"start_time":"2021-11-16T19:33:11.071117","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score\n","\n","\n","def get_logger(filename='inference'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{},"source":["# OOF"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:11:15.028338Z","iopub.status.busy":"2022-02-25T12:11:15.028119Z","iopub.status.idle":"2022-02-25T12:12:01.579645Z","shell.execute_reply":"2022-02-25T12:12:01.578475Z","shell.execute_reply.started":"2022-02-25T12:11:15.02831Z"},"trusted":true},"outputs":[],"source":["# ====================================================\n","# oof\n","# ====================================================\n","oof = pd.read_pickle(CFG.oof_path)\n","\n","truths = create_labels_for_scoring(oof)\n","char_probs = get_char_probs(oof['pn_history'].values,\n","                            oof[[i for i in range(CFG.max_len)]].values, \n","                            CFG.tokenizer)\n","best_th = 0.5\n","best_score = 0.\n","for th in np.arange(0.45, 0.55, 0.01):\n","    th = np.round(th, 2)\n","    results = get_results(char_probs, th=th)\n","    preds = get_predictions(results)\n","    score = get_score(preds, truths)\n","    if best_score < score:\n","        best_th = th\n","        best_score = score\n","    LOGGER.info(f\"th: {th}  score: {score:.5f}\")\n","LOGGER.info(f\"best_th: {best_th}  score: {best_score:.5f}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.018406,"end_time":"2021-11-16T19:33:11.150174","exception":false,"start_time":"2021-11-16T19:33:11.131768","status":"completed"},"tags":[]},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:12:01.581236Z","iopub.status.busy":"2022-02-25T12:12:01.580998Z","iopub.status.idle":"2022-02-25T12:12:02.384993Z","shell.execute_reply":"2022-02-25T12:12:02.384164Z","shell.execute_reply.started":"2022-02-25T12:12:01.581208Z"},"papermill":{"duration":0.637101,"end_time":"2021-11-16T19:33:11.805349","exception":false,"start_time":"2021-11-16T19:33:11.168248","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","test = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\n","submission = pd.read_csv('../input/nbme-score-clinical-patient-notes/sample_submission.csv')\n","features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\n","def preprocess_features(features):\n","    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","features = preprocess_features(features)\n","patient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n","\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"features.shape: {features.shape}\")\n","display(features.head())\n","print(f\"patient_notes.shape: {patient_notes.shape}\")\n","display(patient_notes.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:12:02.386606Z","iopub.status.busy":"2022-02-25T12:12:02.386363Z","iopub.status.idle":"2022-02-25T12:12:02.423336Z","shell.execute_reply":"2022-02-25T12:12:02.422504Z","shell.execute_reply.started":"2022-02-25T12:12:02.386578Z"},"trusted":true},"outputs":[],"source":["test = test.merge(features, on=['feature_num', 'case_num'], how='left')\n","test = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n","display(test.head())"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:12:02.425609Z","iopub.status.busy":"2022-02-25T12:12:02.424784Z","iopub.status.idle":"2022-02-25T12:12:02.435334Z","shell.execute_reply":"2022-02-25T12:12:02.434354Z","shell.execute_reply.started":"2022-02-25T12:12:02.425564Z"},"papermill":{"duration":0.040128,"end_time":"2021-11-16T19:33:20.931029","exception":false,"start_time":"2021-11-16T19:33:20.890901","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, feature_text):\n","    inputs = cfg.tokenizer(text, feature_text, \n","                           add_special_tokens=True,\n","                           max_length=CFG.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.feature_texts = df['feature_text'].values\n","        self.pn_historys = df['pn_history'].values\n","\n","    def __len__(self):\n","        return len(self.feature_texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, \n","                               self.pn_historys[item], \n","                               self.feature_texts[item])\n","        return inputs"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.02209,"end_time":"2021-11-16T19:33:20.978793","exception":false,"start_time":"2021-11-16T19:33:20.956703","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:15:35.383072Z","iopub.status.busy":"2022-02-25T12:15:35.38245Z","iopub.status.idle":"2022-02-25T12:15:35.401004Z","shell.execute_reply":"2022-02-25T12:15:35.399948Z","shell.execute_reply.started":"2022-02-25T12:15:35.383028Z"},"papermill":{"duration":0.032939,"end_time":"2021-11-16T19:33:21.034275","exception":false,"start_time":"2021-11-16T19:33:21.001336","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","def init_params(module_lst):\n","    for module in module_lst:\n","        for param in module.parameters():\n","            if param.dim() > 1:\n","                torch.nn.init.xavier_uniform_(param)\n","    return\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        #self.fc = nn.Linear(self.config.hidden_size, 1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n","            nn.LayerNorm(self.config.hidden_size),\n","            nn.Dropout(0.2),\n","            nn.ReLU(),\n","            nn.Linear(self.config.hidden_size, 1),\n","        )\n","        init_params([self.classifier])\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        return last_hidden_states\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.classifier(feature)\n","        return output"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.022058,"end_time":"2021-11-16T19:33:21.081885","exception":false,"start_time":"2021-11-16T19:33:21.059827","status":"completed"},"tags":[]},"source":["# inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:15:35.662755Z","iopub.status.busy":"2022-02-25T12:15:35.662476Z","iopub.status.idle":"2022-02-25T12:15:35.670476Z","shell.execute_reply":"2022-02-25T12:15:35.669514Z","shell.execute_reply.started":"2022-02-25T12:15:35.662726Z"},"papermill":{"duration":0.044153,"end_time":"2021-11-16T19:33:21.148373","exception":false,"start_time":"2021-11-16T19:33:21.10422","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# inference\n","# ====================================================\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-02-25T12:17:24.174632Z","iopub.status.busy":"2022-02-25T12:17:24.17432Z","iopub.status.idle":"2022-02-25T12:20:49.878355Z","shell.execute_reply":"2022-02-25T12:20:49.877151Z","shell.execute_reply.started":"2022-02-25T12:17:24.174598Z"},"trusted":true},"outputs":[],"source":["test_dataset = TestDataset(CFG, test)\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=CFG.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","predictions = []\n","for m in CFG.trained_models:\n","    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n","    state = torch.load(os.path.join(CFG.dir_path, m),\n","                           map_location=torch.device('cpu'))         \n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader, model, device)\n","    prediction = prediction.reshape((len(test), CFG.max_len))\n","    char_probs = get_char_probs(test['pn_history'].values, prediction, CFG.tokenizer)\n","    predictions.append(char_probs)\n","    del model, state, prediction, char_probs; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions = np.mean(predictions, axis=0)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-25T12:20:49.885004Z","iopub.status.busy":"2022-02-25T12:20:49.884338Z","iopub.status.idle":"2022-02-25T12:20:49.960029Z","shell.execute_reply":"2022-02-25T12:20:49.959233Z","shell.execute_reply.started":"2022-02-25T12:20:49.884952Z"},"trusted":true},"outputs":[],"source":["results = get_results(predictions, th=best_th)\n","submission['location'] = results\n","display(submission.head())\n","submission[['id', 'location']].to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
